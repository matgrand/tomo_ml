{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn import Module, Linear, Conv2d, MaxPool2d, BatchNorm2d, ReLU, Sequential, ConvTranspose2d\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import scipy.io as sio\n",
    "from time import time, sleep\n",
    "import numpy as np\n",
    "from numpy import pi as π\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"darkgrid\")  # adds seaborn style to charts, eg. grid\n",
    "plt.style.use(\"dark_background\")  # inverts colors to dark theme\n",
    "plt.rcParams['font.family'] = 'monospace'\n",
    "np.set_printoptions(precision=3) # set precision for printing numpy arrays\n",
    "import os\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "try: \n",
    "    JOBID = os.environ[\"SLURM_JOB_ID\"] # get job id from slurm, when training on cluster\n",
    "    device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\") # nvidia\n",
    "    HAS_SCREEN = False # for plotting or saving images\n",
    "except:\n",
    "    device = torch.device(\"mps\") # apple silicon\n",
    "    JOBID = \"local\"\n",
    "    HAS_SCREEN = True\n",
    "os.makedirs(f\"mg_data/{JOBID}\", exist_ok=True)\n",
    "print(f'device: {device}')\n",
    "\n",
    "def to_tensor(x, device=torch.device(\"cpu\")): return torch.tensor(x, dtype=torch.float32, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "SXRV_SIZE = 21 #21 # number of vertical sensors (match with dataset)\n",
    "SXRH_SIZE = 23 #23 # number of horizontal sensors (match with dataset)\n",
    "INPUT_SIZE = SXRH_SIZE + SXRV_SIZE\n",
    "# KHR = 8 # multiplier for high resolution\n",
    "# SXR_HR_SIZE = INPUT_SIZE*KHR # high resolution size\n",
    "TRAIN_DS_PATH = \"data/sxr_sg_ds_10000.npz\"\n",
    "EVAL_DS_PATH = \"data/sxr_sg_ds_1000.npz\"\n",
    "# TRAIN_DS_PATH = \"data/sxr_sg_ds_100000.npz\"\n",
    "# EVAL_DS_PATH = \"data/sxr_sg_ds_10000.npz\"\n",
    "BATCH_SIZE = 1\n",
    "LOAD_PRETRAINED = None\n",
    "EPOCHS = 10\n",
    "LEARNING_RATE = np.ones(EPOCHS) * 3e-4 # learning rate\n",
    "\n",
    "SAVE_DIR = f\"mg_data/{JOBID}/sg\" \n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "# copy the python training to the directory (for cluster) (for local, it fails silently)\n",
    "os.system(f\"cp train.py {SAVE_DIR}/train.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "class SXRDataset(Dataset):\n",
    "    def __init__(self, ds_path):\n",
    "        ds = np.load(ds_path)\n",
    "        # self.emiss = to_tensor(ds['emiss'], device)\n",
    "        sxrh = ds['sxrh'] # soft x ray horizontal\n",
    "        sxrv = ds['sxrv'] # soft x ray vertical\n",
    "        self.sxr = to_tensor(np.concatenate([sxrh, sxrv], axis=-1), device)\n",
    "        self.rr = to_tensor(ds['rr'], device).view(-1,1,64,64)\n",
    "        self.zz = to_tensor(ds['zz'], device).view(-1,1,64,64)\n",
    "        self.em = to_tensor(ds['emiss_sg'], device)\n",
    "        assert len(self.em) == len(self.sxr), f'length mismatch: {len(self.em)} vs {len(self.sxr)}'\n",
    "        assert self.sxr.shape[-1] == INPUT_SIZE, f'sxr size mismatch: {self.sxr.shape[-1]}'\n",
    "        # print(f\"dataset: emiss: {self.emiss.shape}, sxr: {self.sxr.shape}, sxr_hr: {self.sxr_hr.shape}\")\n",
    "    def __len__(self): return len(self.sxr)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.sxr[idx], self.em[idx], self.rr[idx], self.zz[idx]\n",
    "\n",
    "# test dataset\n",
    "ds = SXRDataset('data/sxr_sg_ds_1000.npz')\n",
    "print(f'ds len: {len(ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "ds = SXRDataset(EVAL_DS_PATH)\n",
    "print(f\"Dataset length: {len(ds)}\")\n",
    "print(f\"Input shape: {ds[0][0].shape}\")\n",
    "print(f\"Output shape: {ds[0][1].shape}\")\n",
    "n_plot = 10\n",
    "print(len(ds))\n",
    "fig, axs = plt.subplots(2, n_plot, figsize=(3*n_plot, 5))\n",
    "for i, j in enumerate(np.random.randint(0, len(ds), n_plot)):\n",
    "    sxr, em, rr, zz = ds[j][0].cpu().numpy().squeeze(), ds[j][1].cpu().numpy().squeeze(), ds[j][2].cpu().numpy().squeeze(), ds[j][3].cpu().numpy().squeeze()\n",
    "    axs[0,i].contourf(rr, zz, em, 100, cmap=\"inferno\")\n",
    "    axs[0,i].contour(rr, zz, -em, 20, colors=\"black\", linestyles=\"dotted\")\n",
    "    axs[0,i].axis(\"off\")\n",
    "    axs[0,i].set_aspect(\"equal\")\n",
    "    #plot sxr\n",
    "    axs[1,i].plot(sxr)\n",
    "plt.show() if HAS_SCREEN else plt.savefig(f\"mg_data/{JOBID}/dataset.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# activation functions\n",
    "class Swish(Module): # custom trainable swish\n",
    "    def __init__(self, β=1.0): \n",
    "        super(Swish, self).__init__()\n",
    "        self.β = torch.nn.Parameter(torch.tensor(β), requires_grad=True)\n",
    "    def forward(self, x): \n",
    "        return x*torch.sigmoid(self.β*x)\n",
    "    def to(self, device): \n",
    "        self.β = self.β.to(device)\n",
    "        return super().to(device)\n",
    "\n",
    "# class Λ(Module): # relu, uncomment for relu activation\n",
    "#     def __init__(self): super(Λ, self).__init__()\n",
    "#     def forward(self, x): return torch.relu(x)\n",
    "\n",
    "class Λ(Module): # swish, uncomment for swish activation\n",
    "    def __init__(self): \n",
    "        super(Λ, self).__init__()\n",
    "        self.β = torch.nn.Parameter(torch.tensor(1.0), requires_grad=True)\n",
    "    def forward(self, x): return x*torch.sigmoid(self.β*x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL: VERY BIG SXRNet: # SAME NET, BUT MORE NEURONS\n",
    "class SXRNet(Module): # Paper net: branch + trunk conenction and everything\n",
    "    def __init__(self):\n",
    "        super(SXRNet, self).__init__()\n",
    "        #branch\n",
    "        self.branch = Sequential(\n",
    "            Linear(INPUT_SIZE, 256), Λ(),\n",
    "            Linear(256, 128), Λ(),\n",
    "            Linear(128, 64), Λ(),\n",
    "        )\n",
    "        #trunk\n",
    "        def trunk_block(): \n",
    "            return  Sequential(\n",
    "                Conv2d(1, 8, kernel_size=3, stride=1, padding=1), BatchNorm2d(8), Λ(), MaxPool2d(2),\n",
    "                Conv2d(8, 16, kernel_size=3, stride=1, padding=1), BatchNorm2d(16), Λ(), MaxPool2d(2),\n",
    "                Conv2d(16, 32, kernel_size=3, stride=1, padding=1), BatchNorm2d(32), Λ(), MaxPool2d(2),\n",
    "            )\n",
    "        self.trunk_r, self.trunk_z = trunk_block(), trunk_block()\n",
    "        self.trunk_fc = Sequential(\n",
    "            Linear(2*32*8*8, 128), Λ(),\n",
    "            Linear(128, 64), Λ(),\n",
    "            Linear(64, 64), Λ(), \n",
    "        )\n",
    "        # head\n",
    "        self.fc = Sequential(Linear(64, 4096), Λ())\n",
    "        self.anti_conv = Sequential( # U-Net style\n",
    "            ConvTranspose2d(64, 64, kernel_size=2, stride=2), \n",
    "            Conv2d(64, 64, kernel_size=3, padding=0), Λ(),\n",
    "            Conv2d(64, 64, kernel_size=3, padding=0), Λ(),\n",
    "            ConvTranspose2d(64, 32, kernel_size=2, stride=2),\n",
    "            Conv2d(32, 32, kernel_size=3, padding=0), Λ(),\n",
    "            Conv2d(32, 32, kernel_size=3, padding=0), Λ(),\n",
    "            ConvTranspose2d(32, 16, kernel_size=2, stride=2),\n",
    "            Conv2d(16, 16, kernel_size=3, padding=0), Λ(),\n",
    "            Conv2d(16, 16, kernel_size=3, padding=0), Λ(),\n",
    "            ConvTranspose2d(16, 8, kernel_size=2, stride=2),\n",
    "            Conv2d(8, 4, kernel_size=3, padding=0), Λ(),\n",
    "            Conv2d(4, 2, kernel_size=3, padding=0), Λ(),\n",
    "            Conv2d(2, 1, kernel_size=5, padding=0),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        xb, r, z = x\n",
    "        #branch net\n",
    "        xb = self.branch(xb)\n",
    "        #trunk net\n",
    "        r, z = self.trunk_r(r), self.trunk_z(z) # convolutions\n",
    "        r, z = r.view(-1, 32*8*8), z.view(-1, 32*8*8) # flatten\n",
    "        xt = torch.cat((r, z), 1) # concatenate\n",
    "        xt = self.trunk_fc(xt) # fully connected\n",
    "        # multiply trunk and branch\n",
    "        x = xt * xb\n",
    "        #head net\n",
    "        x = self.fc(x)\n",
    "        x = x.view(-1, 64, 8, 8)\n",
    "        x = self.anti_conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test model\n",
    "model = SXRNet()\n",
    "input = (torch.randn(1, INPUT_SIZE), torch.randn(1, 1, 64, 64), torch.randn(1, 1, 64, 64))\n",
    "output = model(input)\n",
    "print(f'Input: {input[0].shape}, {input[1].shape}, {input[2].shape}, \\nOutput: {output.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    train_ds, val_ds = SXRDataset(TRAIN_DS_PATH), SXRDataset(EVAL_DS_PATH) # initialize datasets\n",
    "    train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True) # initialize DataLoader\n",
    "    val_dl = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False)  \n",
    "    model = SXRNet()  # instantiate model\n",
    "    if LOAD_PRETRAINED is not None: # load pretrained model\n",
    "        model.load_state_dict(torch.load(LOAD_PRETRAINED, map_location=torch.device(\"cpu\"))) # load pretrained model\n",
    "        print(f\"Pretrained model loaded: {LOAD_PRETRAINED}\")\n",
    "    model.to(device) # move model to device\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE[0])\n",
    "    loss_fn = torch.nn.MSELoss() # Mean Squared Error Loss\n",
    "    tlog_tot, elog_tot = [], []# logs for losses\n",
    "    start_time = time() # start time\n",
    "    for ep in range(EPOCHS): # epochs\n",
    "        epoch_time = time()\n",
    "        for pg in optimizer.param_groups: pg['lr'] = LEARNING_RATE[ep] # update learning rate\n",
    "        model.train()\n",
    "        trainloss, evalloss = [], []\n",
    "        for sxr, em, rr, zz in train_dl:\n",
    "            optimizer.zero_grad() # zero gradients\n",
    "            em_pred = model((sxr, rr, zz)) # forward pass\n",
    "            loss = loss_fn(em_pred, em) # mean squared error loss on em\n",
    "            loss.backward() # backprop\n",
    "            optimizer.step() # update weights\n",
    "            trainloss.append((loss.item())) # save batch losses\n",
    "        model.eval() # evaluation mode\n",
    "        with torch.no_grad():\n",
    "            for sxr, em, rr, zz in val_dl:\n",
    "                em_pred = model((sxr, rr, zz))\n",
    "                loss = loss_fn(em_pred, em)\n",
    "                evalloss.append((loss.item()))\n",
    "        tloss_tot = sum(trainloss)/len(trainloss) # average train loss\n",
    "        eloss_tot = sum(evalloss)/len(evalloss) # average eval loss\n",
    "        # save model if improved        \n",
    "        if eloss_tot <= min(elog_tot, default=eloss_tot): \n",
    "            torch.save(model.state_dict(), f\"{SAVE_DIR}/mg_planet_tot.pth\"); endp=\" *\\n\"\n",
    "        else: endp = \"\\n\"\n",
    "        tlog_tot.append(tloss_tot) \n",
    "        elog_tot.append(eloss_tot)\n",
    "        print(f\"{ep+1}/{EPOCHS}: \"\n",
    "            f\"Eval: loss {eloss_tot:.4f} | \" + \n",
    "            f\"lr:{LEARNING_RATE[ep]:.1e} | \" + \n",
    "            f\"{time()-epoch_time:.0f}s, eta:{(time()-start_time)*(EPOCHS-ep)/(ep+1)/60:.0f}m |\", end=endp,  flush=True)\n",
    "        if ep >= 10 and eloss_tot > 9.0: return False, () # stop training, if not converging, try again\n",
    "    print(f\"Training time: {(time()-start_time)/60:.0f}mins\")\n",
    "    print(f\"Best losses: tot {min(elog_tot):.4f}\")\n",
    "    for l, n in zip([tlog_tot], [\"tot\"]): np.save(f\"{SAVE_DIR}/train_{n}_losses.npy\", l) # save losses\n",
    "    for l, n in zip([elog_tot], [\"tot\"]): np.save(f\"{SAVE_DIR}/eval_{n}_losses.npy\", l) # save losses\n",
    "    return True, (tlog_tot, elog_tot)\n",
    "\n",
    "# train the model (multiple attempts)\n",
    "for i in range(10): \n",
    "    success, logs = train()\n",
    "    if success: tlog_tot, elog_tot = logs; break\n",
    "    else: print(f\"Convergence failed, retrying... {i+1}/10\")\n",
    "assert success, \"Training failed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot losses\n",
    "fig, ax = plt.subplots(2, 3, figsize=(12, 6))\n",
    "ce, ct = \"yellow\", \"red\"\n",
    "lw = 1.0\n",
    "ax[0,0].set_title(\"TOT Loss\")\n",
    "ax[0,0].plot(tlog_tot, color=ct, label=\"train\", linewidth=lw)\n",
    "ax[0,0].plot(elog_tot, color=ce, label=\"eval\", linewidth=lw)\n",
    "# ax[0,1].set_title(\"MSE Loss\")\n",
    "# ax[0,1].plot(tlog_mse, color=ct, label=\"train\", linewidth=lw)\n",
    "# ax[0,1].plot(elog_mse, color=ce, label=\"eval\", linewidth=lw)\n",
    "# ax[0,2].set_title(\"GSO Loss\")\n",
    "# ax[0,2].plot(tlog_gso, color=ct, label=\"train\", linewidth=lw)\n",
    "# ax[0,2].plot(elog_gso, color=ce, label=\"eval\", linewidth=lw)\n",
    "\n",
    "#now the same but with log scale\n",
    "ax[1,0].set_title(\"TOT Loss (log)\")\n",
    "ax[1,0].plot(tlog_tot, color=ct, label=\"train\", linewidth=lw)\n",
    "ax[1,0].plot(elog_tot, color=ce, label=\"eval\", linewidth=lw)\n",
    "ax[1,0].set_yscale(\"log\")\n",
    "ax[1,0].grid(True, which=\"both\", axis=\"y\")\n",
    "\n",
    "# ax[1,1].set_title(\"MSE Loss (log)\")\n",
    "# ax[1,1].plot(tlog_mse, color=ct, label=\"train\", linewidth=lw)\n",
    "# ax[1,1].plot(elog_mse, color=ce, label=\"eval\", linewidth=lw)\n",
    "# ax[1,1].set_yscale(\"log\")\n",
    "# ax[1,1].grid(True, which=\"both\", axis=\"y\")\n",
    "\n",
    "# ax[1,2].set_title(\"GSO Loss (log)\")\n",
    "# ax[1,2].plot(tlog_gso, color=ct, label=\"train\", linewidth=lw)\n",
    "# ax[1,2].plot(elog_gso, color=ce, label=\"eval\", linewidth=lw)\n",
    "# ax[1,2].set_yscale(\"log\")\n",
    "# ax[1,2].grid(True, which=\"both\", axis=\"y\")\n",
    "\n",
    "for a in ax.flatten(): a.legend(); a.set_xlabel(\"Epoch\"); a.set_ylabel(\"Loss\")\n",
    "plt.tight_layout()\n",
    "plt.show() if HAS_SCREEN else plt.savefig(f\"mg_data/{JOBID}/losses.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing network output\n",
    "for titl, best_model_path in zip([\"TOT\"], [\"mg_planet_tot.pth\"]):\n",
    "    model = SXRNet()\n",
    "    model.load_state_dict(torch.load(f\"{SAVE_DIR}/{best_model_path}\"))\n",
    "    model.eval()\n",
    "    ds = SXRDataset(EVAL_DS_PATH)\n",
    "    # ds = SXRDataset(TRAIN_DS_PATH)\n",
    "    os.makedirs(f\"mg_data/{JOBID}/imgs\", exist_ok=True)\n",
    "    N_PLOTS = 2 if HAS_SCREEN else 50\n",
    "    for i in np.random.randint(0, len(ds), N_PLOTS):  \n",
    "        fig, axs = plt.subplots(2, 5, figsize=(15, 9))\n",
    "        sxr, em_ds, rr, zz = ds[i]\n",
    "        sxr, em_ds, rr, zz = sxr.to('cpu'), em_ds.to('cpu'), rr.to('cpu'), zz.to('cpu')\n",
    "        sxr, em_ds, rr, zz = sxr.view(1,-1), em_ds.view(1,1,64,64), rr.view(1,1,64,64), zz.view(1,1,64,64)\n",
    "        em_pred = model((sxr, rr, zz))\n",
    "        \n",
    "        em_pred = em_pred.detach().numpy().reshape(64, 64)\n",
    "        em_ds = em_ds.detach().numpy().reshape(64, 64)\n",
    "        rr, zz = rr.view(64, 64).detach().numpy(), zz.view(64, 64).detach().numpy()\n",
    "        ext = [ds.rr.min(), ds.rr.max(), ds.zz.min(), ds.zz.max()]\n",
    "        bmin, bmax = np.min([em_ds, em_pred]), np.max([em_ds, em_pred]) # min max em\n",
    "        blevels = np.linspace(bmin, bmax, 13, endpoint=True)\n",
    "        em_mse = (em_ds - em_pred)**2\n",
    "        mse_levels1 = np.linspace(0, 0.5, 13, endpoint=True)\n",
    "        mse_levels2 = np.linspace(0, 0.05, 13, endpoint=True)\n",
    "\n",
    "        im00 = axs[0,0].contourf(rr, zz, em_ds, blevels, cmap=\"inferno\")\n",
    "        axs[0,0].set_title(\"Actual\")\n",
    "        axs[0,0].set_aspect('equal')\n",
    "        axs[0,0].set_ylabel(\"em\")\n",
    "        fig.colorbar(im00, ax=axs[0,0]) \n",
    "        im01 = axs[0,1].contourf(rr, zz, em_pred, blevels, cmap=\"inferno\")\n",
    "        axs[0,1].set_title(\"Predicted\")\n",
    "        fig.colorbar(im01, ax=axs[0,1])\n",
    "        im02 = axs[0,2].contour(rr, zz, em_ds, blevels, linestyles='dashed', cmap=\"inferno\")\n",
    "        axs[0,2].contour(rr, zz, em_pred, blevels, cmap=\"inferno\")\n",
    "        axs[0,2].set_title(\"Contours\")\n",
    "        fig.colorbar(im02, ax=axs[0,2])\n",
    "        im03 = axs[0,3].contourf(rr, zz, np.clip(em_mse, 0, 0.5), mse_levels1, cmap=\"inferno\")\n",
    "        axs[0,3].set_title(\"MSE 0.5\")\n",
    "        fig.colorbar(im03, ax=axs[0,3])\n",
    "        im04 = axs[0,4].contourf(rr, zz, np.clip(em_mse, 0.00001, 0.04999), mse_levels2, cmap=\"inferno\")\n",
    "        axs[0,4].set_title(\"MSE 0.05\")\n",
    "        fig.colorbar(im04, ax=axs[0,4])\n",
    "        # im10 = axs[1,0].contourf(rr, zz, gso, gso_levels, cmap=\"inferno\")\n",
    "        axs[1,0].set_ylabel(\"GSO\")\n",
    "        # fig.colorbar(im10, ax=axs[1,0])\n",
    "        # im6 = axs[1,1].contourf(rr, zz, gso_pred, gso_levels, cmap=\"inferno\")\n",
    "        # fig.colorbar(im6, ax=axs[1,1])\n",
    "        # im12 = axs[1,2].contour(rr, zz, gso, gso_levels, linestyles='dashed', cmap=\"inferno\")\n",
    "        # axs[1,2].contour(rr, zz, gso_pred, gso_levels, cmap=\"inferno\")\n",
    "        # fig.colorbar(im12, ax=axs[1,2])\n",
    "        # im13 = axs[1,3].contourf(rr, zz, np.clip(gso_mse, 0, 0.5), mse_levels1, cmap=\"inferno\")\n",
    "        # fig.colorbar(im13, ax=axs[1,3])\n",
    "        # im14 = axs[1,4].contourf(rr, zz, np.clip(gso_mse, 0.00001, 0.04999), mse_levels2, cmap=\"inferno\")\n",
    "        # fig.colorbar(im14, ax=axs[1,4])\n",
    "\n",
    "        for ax in axs.flatten(): ax.grid(False), ax.set_xticks([]), ax.set_yticks([]), ax.set_aspect(\"equal\")\n",
    "\n",
    "        #suptitle\n",
    "        plt.suptitle(f\"SXRNet: {titl} {i}\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        os.makedirs(f\"{SAVE_DIR}/imgs\", exist_ok=True)\n",
    "        plt.show() if HAS_SCREEN else plt.savefig(f\"{SAVE_DIR}/imgs/{titl}_{i}.png\")\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test inference speed\n",
    "model = SXRNet()\n",
    "model.load_state_dict(torch.load(f\"{SAVE_DIR}/{best_model_path}\"))\n",
    "model.eval()\n",
    "ds = SXRDataset(EVAL_DS_PATH)\n",
    "n_samples = 100\n",
    "random_idxs = np.random.choice(n_samples, len(ds))\n",
    "#cpu\n",
    "cpu_times = []\n",
    "for i in random_idxs:\n",
    "    start_t = time()\n",
    "    sxr, em_ds, rr, zz = ds[i]\n",
    "    sxr, em_ds, rr, zz = sxr.to('cpu'), em_ds.to('cpu'), rr.to('cpu'), zz.to('cpu')\n",
    "    sxr, em_ds, rr, zz = sxr.view(1,-1), em_ds.view(1,1,64,64), rr.view(1,1,64,64), zz.view(1,1,64,64)\n",
    "    em_pred = model((sxr, rr, zz))\n",
    "    end_t = time()\n",
    "    cpu_times.append(end_t - start_t) \n",
    "# device\n",
    "model.to(device)\n",
    "dev_times = []\n",
    "for i in random_idxs:\n",
    "    sxr, em_ds, rr, zz = ds[i]\n",
    "    sxr, em_ds, rr, zz = sxr.view(1,-1), em_ds.view(1,1,64,64), rr.view(1,1,64,64), zz.view(1,1,64,64)\n",
    "    start_t = time()\n",
    "    em_pred = model((sxr, rr, zz))\n",
    "    end_t = time()\n",
    "    dev_times.append(end_t - start_t)    \n",
    "cpu_times, dev_times = np.array(cpu_times), np.array(dev_times)\n",
    "print(f\"cpu: inference time: {cpu_times.mean():.5f}s, std: {cpu_times.std():.5f}\")\n",
    "print(f\"dev: inference time: {dev_times.mean():.5f}s, std: {dev_times.std():.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "RES = 64 # [#] resolution of the grid in pixels (square grid)\n",
    "L = 1.0 # [m] length of the grid in the r/x direction (square grid)\n",
    "R0 = 1.5 # [m] grid start in the r/x direction\n",
    "Z0 = -0.5 # [m] grid start in the z/y direction\n",
    "R1, Z1 = R0+L, Z0+L # [m] grid ends in the r/x and z/y direction\n",
    "RM, ZM = 0.5*(R0+R1), 0.5*(Z0+Z1) # [m] grid center in the x/r and z direction\n",
    "# calculated constants\n",
    "R = np.linspace(R0, R1, RES)\n",
    "Z = np.linspace(Z0, Z1, RES)\n",
    "assert np.isclose(R1-R0, Z1-Z0), \"grid must be square\"\n",
    "δ = L/RES # [m] grid spacing\n",
    "RR, ZZ = np.meshgrid(R, Z) # create a grid of R and Z values\n",
    "RZ = np.stack((RR, ZZ), axis=-1) # create a grid of R and Z values"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
